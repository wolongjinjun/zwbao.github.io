# 宏基因组实战

> 整理自：https://github.com/LangilleLab/microbiome_helper/wiki/Metagenomics-standard-operating-procedure-v2

## 所需软件

你可以在这个[GitHub仓库](https://github.com/LangilleLab/microbiome_helper)得到一些用于衔接各个软件的脚本。

- FastQC (可选): <http://www.bioinformatics.babraham.ac.uk/projects/fastqc/>

**FastQC**是一款基于Java的软件，它可以快速地对测序数据进行质量评估（Quality Control）。

- Bowtie2: <http://bowtie-bio.sourceforge.net/bowtie2/index.shtml>

**Bowtie 2**用于将测序`reads`与长参考序列进行比对，擅长于比对约50至100或1,000个字符的`reads`，同时也擅长与相对较大（例如哺乳动物）的基因组比对。

- DIAMOND (> v.0.7.0): <http://ab.inf.uni-tuebingen.de/software/diamond/>

**DIAMOND**用于将`reads`或蛋白质序列与蛋白质参考数据库（如NR）进行比对，速度高达BLAST的20,000倍，具有高灵敏性。

- Human pre-indexed database: <ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/hg19.zip>

人类参考基因组bowtie2的index文件，也可用`bowtie2-build`命令生成。

- HUMAnN2: <http://huttenhower.sph.harvard.edu/humann2>

**HUMAnN2**是用于从宏基因组或宏转录组测序数据中高效准确地分析群落中微生物的组成在和丰度的流程。其输出文件包括基因家族文件，通路丰度文件以及通路覆盖度文件。

- GNU Parallel (>= v20170322): <https://www.gnu.org/software/parallel/>

**GNU parallel**是处理重复命令时十分有用的工具， 这在生物信息学中尤其常用，因为我们通常希望在大批文件上运行完全相同的命令，同时以并行方式执行任务。
> 教程可参见： https://github.com/LangilleLab/microbiome_helper/wiki/Quick-Introduction-to-GNU-Parallel

- kneadData: <https://bitbucket.org/biobakery/kneaddata/wiki/Home>

**KneadData**用于对宏基因组和宏转录组测序数据进行质量控制。在这些实验中，样品通常取自宿主，希望研究宿主上的微生物群落。 然而，来自此类实验的测序数据通常包含高比例的宿主与细菌`reads`。该工具旨在对来自这些“污染物”的`reads`分离。

- MetaPhlAn2: <https://bitbucket.org/biobakery/metaphlan2>

**MetaPhlAn2**用于从宏基因组测序数据中分析微生物群落（细菌，古细菌，真核生物和病毒）的组成。

- PEAR: <http://sco.h-its.org/exelixis/web/software/pear/doc.html>

**PEAR**会快速，高效且精确地将双端`reads`进行合并。

- Trimmomatic: <http://www.usadellab.org/cms/?page=trimmomatic>

**Trimmomatic**用于Illumina双端和单端测序数据的各种`trim`任务。

- STAMP: <http://kiwi.cs.dal.ca/Software/STAMP>

**STAMP**用于比较不同处理组之间差异物种或差异基因。该软件不仅能够对两组甚至多组样本及两两样本之间的KEGG、COG、基因及任何分类水平的物种等进行显著性差异分析，同时带有10多种可选择的差异检验方法以及图形展示形式（柱状图，散点图，热图，PCA图等）。

## 实战

注意：

- 以下选项不一定适合您的数据; 探索不同的选项很重要，特别是在`reads`质量过滤阶段。
- 如果你对特定步骤感到困惑，请务必查看右侧栏上`Metagenomic Resources`下的页面。
- 你应该检查每个步骤是否仅指定了正确的FASTQ文件（例如，使用ls命令）， 如果要多次重新运行命令或使用可选步骤，则输入文件名和/或文件夹可能会有所不同。
- 在此工作流程中，`parallel`工具会多次出现。请务必在[此处](https://github.com/LangilleLab/microbiome_helper/wiki/Quick-Introduction-to-GNU-Parallel)查看有关此工具的教程。
- 建议在使用使用`parallel`时选用`--dry-run`选项运行，以查看正在运行的命令，以便仔细检查它们是否正在执行你想要的操作！

这份流程可用于双端测序的*Miseq* 或 *NextSeq* fastq文件，这些文件存放于`raw_data`文件夹。

**Step 1** （可选）将多个测序泳道数据连接在一起（例如，用于 *NextSeq*  数据）。如果你执行此步骤，请记住将`raw_data`更改为`concat_data`。
```
concat_lanes.pl raw_data/* -o concat_data -p 4
```
**Step 2**  使用`fastqc`检查测序质量。
```
mkdir fastqc_out
fastqc -t 4 raw_data/* -o fastqc_out/
```
**Step 3**  （可选）合并双端`reads`（结果汇总见`pear_summary_log.txt`）。注意：检查组装的百分比很重要。如果`reads`组装的`%`太低，将正向和反向`reads`连接在一起可能会更好（见第六步）。
```
run_pear.pl -p 4 -o stitched_reads raw_data/*
```
*如果在此步骤中你没有将reads拼接在一起，则需要在运行以下命令之前解压缩fastq文件。*
> 需要安装Perl模块`Parallel::ForkManager`
**Step 4**  使用`kneaddata`运行预处理工具。首先运行`trimmomatic`以删除低质量序列。然后运行`bowtie2`以筛选出污染序列。接下来，筛选出映射到人类基因组的`reads`。注意，在这里我们用`parralel`对`kneaddata`进行并行运算，点击[这里](https://github.com/LangilleLab/microbiome_helper/wiki/Quick-Introduction-to-GNU-Parallel)看到我们关于这个工具的快速教程。有关以下命令中的选项的详细介绍，请参阅此[页面](https://github.com/LangilleLab/microbiome_helper/wiki/Metagenomics-Sequencing-Pre-processing)。正向和反向`reads`将由输出文件中的`_1`和`_2`指定。注意，每行末尾的`\`只是将命令分成多行，以便于阅读，没别的意思。

```
parallel -j 1 --link 'kneaddata -i {1} -i {2} -o kneaddata_out/ \
-db /home/shared/bowtiedb/GRCh38_PhiX --trimmomatic /usr/local/prg/Trimmomatic-0.36/ \
-t 4 --trimmomatic-options "SLIDINGWINDOW:4:20 MINLEN:50" \
--bowtie2-options "--very-sensitive --dovetail" --remove-intermediate-output' \
 ::: raw_data/*_R1.fastq ::: raw_data/*_R2.fastq
```

你也可以使用以下命令生成日志文件：

```
kneaddata_read_count_table --input kneaddata_out --output kneaddata_read_counts.txt
```

**Step 5**  （可选）如果你担心影响样本中测序深度的差异，这可能会有所帮助。请参阅此[页面](https://github.com/LangilleLab/microbiome_helper/wiki/Subsampling-Metagenomic-FASTQs)了解详情。
**Step 6**  （可选）如果你没有用`pear`进行合并双端`reads`，那么你现在可以将正向和反向的`fastq`连接在一起。请注意，这是在质量过滤后完成的，因此一对中的两个读取都将被一起丢弃或保留。注意，我们只需要指定`kneaddata`输出的“配对”的fastq文件。你需要先将污染物的序列移动到单独的文件夹中（下面的前两个命令）。

> 需要安装Perl模块`Parallel::ForkManager`

```
mkdir kneaddata_out/contam_seq

mv kneaddata_out/*_contam_*fastq kneaddata_out/contam_seq

concat_paired_end.pl -p 4 --no_R_match -o cat_reads kneaddata_out/*_paired_*.fastq 
```

你需要检查输出到屏幕的命令，以确保正确的`fastq`连接在一起。

**Step 7**  用`parallel`并行运算`humann2`来计算uniref90基因家族和metacyc通路的丰度。

```
mkdir humann2_out

parallel -j 4 'humann2 --threads 1 --input {} --output humann2_out/{/.}' ::: cat_reads/*fastq
```

> 报错：`The database file for MetaPhlAn does not exist at /data/zwbao/biosoft/metaphlan2/db_v20/mpa_v20_m200.pkl . Please provide the location with --metaphlan-options .
`

> 解决方法：`cd`到`metaphlan2`安装目录下的`db_v20`文件夹中（若没有这个文件夹则新建一个），在 `https://bitbucket.org/biobakery/metaphlan2/downloads/` 下载`mpa_v20_m200.md5`和`mpa_v20_m200.tar`文件，解压`mpa_v20_m200.tar`得到`.fna`和`.pkl`。

**Step 8**  将每个样本的`humann2`输出导入到一个表中。

```
mkdir humann2_final_out

humann2_join_tables -s --input humann2_out/ --file_name pathabundance --output humann2_final_out/humann2_pathabundance.tsv
humann2_join_tables -s --input humann2_out/ --file_name pathcoverage --output humann2_final_out/humann2_pathcoverage.tsv
humann2_join_tables -s --input humann2_out/ --file_name genefamilies --output humann2_final_out/humann2_genefamilies.tsv
```

**Step 9**  重新标准化基因家族和通路的丰度（使每个样本的丰度总和为100）。
```
humann2_renorm_table --input humann2_final_out/humann2_pathabundance.tsv --units relab --output humann2_final_out/humann2_pathabundance_relab.tsv
humann2_renorm_table --input humann2_final_out/humann2_genefamilies.tsv --units relab --output humann2_final_out/humann2_genefamilies_relab.tsv
```

**Step 10**  分割`humann2`输出的丰度表为分层（unclassified）和非分层表。
```
humann2_split_stratified_table --input humann2_final_out/humann2_pathabundance_relab.tsv --output humann2_final_out
humann2_split_stratified_table --input humann2_final_out/humann2_genefamilies_relab.tsv --output humann2_final_out
humann2_split_stratified_table --input humann2_final_out/humann2_pathcoverage.tsv --output humann2_final_out
```

**Step 11**  通过改变标题行将未分层的humann2丰度表转换为`STAMP`格式。这些命令会删除注释字符和第一列名称中的空格。每个样本的列名也会被删除一些描述。

```
sed 's/_Abundance-RPKs//g' humann2_final_out/humann2_genefamilies_relab_unstratified.tsv | sed 's/# Gene Family/GeneFamily/' > humann2_final_out/humann2_genefamilies_relab_unstratified.spf

sed 's/_Abundance//g' humann2_final_out/humann2_pathabundance_relab_unstratified.tsv | sed 's/# Pathway/Pathway/' > humann2_final_out/humann2_pathabundance_relab_unstratified.spf
```

**Step 12**  因为`humann2`也运行`metaphlan2`作为初始步骤，我们可以使用已经创建的输出表来获得我们样本的分类组成。首先，我们需要将每个样本的`metaphlan2`结果收集到一个目录中，然后使用`metaphlan2`的`merge_metaphlan_tables.py`命令将它们合并到一个表中。之后，我们删除`_metaphlan_bugs_list`这串字符。

```
mkdir metaphlan2_out
cp humann2_out/*/*/*metaphlan_bugs_list.tsv metaphlan2_out/
/usr/local/metaphlan2/utils/merge_metaphlan_tables.py metaphlan2_out/*metaphlan_bugs_list.tsv > metaphlan2_merged.txt
sed -i 's/_metaphlan_bugs_list//g' metaphlan2_merged.txt
```

**Step 13**  最后我们将这个`metaphlan2`丰度表转换为`STAMP`格式。

```
metaphlan_to_stamp.pl metaphlan2_merged.txt > metaphlan2_merged.spf
```

